{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INICIANDO PROCESSAMENTO DA TABELA\n",
      "==================================================\n",
      "\n",
      "→ Carregando arquivo: tabelaInicial.xlsx\n",
      "✓ Total de linhas carregadas: 1000\n",
      "→ Limitando aos primeiros 30 itens\n",
      "\n",
      "→ Verificando colunas necessárias...\n",
      "✓ Todas as colunas necessárias encontradas\n",
      "\n",
      "Iniciando processamento de itens...\n",
      "\n",
      "==================================================\n",
      "Processando item: NEVRALGEX DIP 1 G C/ 10 COMP\n",
      "Grupo: Medicamento\n",
      "==================================================\n",
      "→ Verificando itens similares...\n",
      "→ Produtos similares encontrados: []\n",
      "\n",
      "→ Enviando para processamento LLM...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnalise o seguinte item e forneça uma normalização seguindo ESTRITAMENTE as regras e exemplos abaixo:\n",
      "\n",
      "REGRAS DE NORMALIZAÇÃO:\n",
      "\n",
      "1. REGRA PRINCIPAL - Unificação de Medidas:\n",
      "   - SEMPRE ignore TODAS as unidades de medida (ml, g, mg, kg, etc)\n",
      "   - SEMPRE ignore TODAS as quantidades (10 comp, 20 comp, 3 ampolas, etc)\n",
      "   - SEMPRE unifique itens com mesmo nome base, independente das medidas\n",
      "   - Mantenha apenas especificações que mudam a função do produto (ex: FPS)\n",
      "\n",
      "2. Para MARCAS:\n",
      "   - Em cosméticos e materiais: converta para termo genérico\n",
      "   - Em medicamentos: mantenha o nome específico\n",
      "\n",
      "EXEMPLOS DE CONVERSÃO DE MARCAS:\n",
      "- \"Nescau\" → \"Achocolatado em Pó\"\n",
      "- \"Nestogeno\" → \"Fórmula Infantil\"\n",
      "- \"Neutrogena Sun Fresh\" → \"Protetor Solar\"\n",
      "- \"Neosoro\" → \"Soro Fisiológico\"\n",
      "- \"Novalgina\" → \"Dipirona\"\n",
      "- \"Neutrofer\" → \"Sulfato Ferroso\"\n",
      "- \"Ninho\" → \"Leite em Pó\"\n",
      "- \"Neuleptil\" → \"Periciazina\"\n",
      "- \"Nestonutri\" → \"Suplemento Alimentar\"\n",
      "\n",
      "EXEMPLOS DE UNIFICAÇÃO:\n",
      "- \"Soro fisiológico 100ml\" e \"Soro fisiológico 500ml\" → \"Soro fisiológico\"\n",
      "- \"Dipirona 500mg\" e \"Dipirona 1g\" → \"Dipirona\"\n",
      "- \"Papel A4 500 folhas\" e \"Papel A4 100 folhas\" → \"Papel A4\"\n",
      "- \"Álcool 70% 1L\" e \"Álcool 70% 100ml\" → \"Álcool 70%\"\n",
      "- \"Protetor Solar FPS 30 50ml\" e \"Protetor Solar FPS 30 200ml\" → \"Protetor Solar FPS 30\"\n",
      "- \"Luva M cx 100un\" e \"Luva M cx 50un\" → \"Luva M\"\n",
      "- \"Fralda G 20un\" e \"Fralda G 60un\" → \"Fralda G\"\n",
      "\n",
      "EXEMPLOS DE MARCAS:\n",
      "- \"Neutrogena Sun Fresh FPS 30 200ml\" → \"Protetor Solar FPS 30\"\n",
      "- \"Novalgina 500mg 20 comp\" → \"Novalgina\"\n",
      "- \"Nescau 400g\" e \"Nescau 1kg\" → \"achocolatado em pó\"\n",
      "\n",
      "IMPORTANTE:\n",
      "- SEMPRE converta marcas para nomes genéricos dos produtos\n",
      "- Analise o contexto para identificar o produto real\n",
      "- Use termos técnicos/genéricos em vez de marcas\n",
      "- Mantenha apenas características funcionais (FPS, Zero Lactose, etc)\n",
      "- Use letras maiúsculas no início de cada palavra importante\n",
      "- NUNCA faça distinção por quantidade ou unidade de medida\n",
      "- Mantenha apenas características que alteram a função (tamanho P/M/G, FPS, etc)\n",
      "- Unifique SEMPRE produtos com mesmo nome base\n",
      "- Remova TODAS as informações de quantidade/volume/peso\n",
      "\n",
      "Item para análise:\n",
      "- Produto: NEVRALGEX DIP 1 G C/ 10 COMP\n",
      "- Grupo: Medicamento\n",
      "- Já processado antes?: False\n",
      "- Produtos similares já processados: []\n",
      "\n",
      "Responda APENAS no seguinte formato JSON:\n",
      "{\"item_normalizado\": \"Nome Genérico Com Capitalize\", \"categoria\": \"categoria do item\"}\n",
      "\u001b[0m\n",
      "\n",
      "❌ ERRO no processamento LLM:\n",
      "Tipo de erro: RateLimitError\n",
      "Mensagem de erro: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "⚠️  ERRO DE QUOTA DA API OPENAI - Verifique sua chave API\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Erro de quota da API OpenAI - Processamento interrompido",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 251\u001b[39m, in \u001b[36mDocumentFilter._process_item\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m→ Enviando para processamento LLM...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrupo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrupo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mja_processado\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariantes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdetails\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprodutos_similares\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprodutos_similares\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain/chains/base.py:163\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    164\u001b[39m run_manager.on_chain_end(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain/chains/base.py:153\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    152\u001b[39m outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    156\u001b[39m )\n\u001b[32m    158\u001b[39m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    159\u001b[39m     inputs, outputs, return_only_outputs\n\u001b[32m    160\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain/chains/llm.py:103\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m     99\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    100\u001b[39m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    101\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    102\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain/chains/llm.py:115\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:560\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    559\u001b[39m prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    420\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    422\u001b[39m flattened_outputs = [\n\u001b[32m    423\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    425\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:411\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    410\u001b[39m     results.append(\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m            \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:632\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:548\u001b[39m, in \u001b[36mChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m params = {**params, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:275\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/resources/chat/completions.py:829\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    828\u001b[39m validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1280\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1277\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1278\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1279\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:957\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    955\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1046\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1045\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1095\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1093\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1046\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1045\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1095\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1093\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/ajulabs/docs_filter/.venv/lib/python3.13/site-packages/openai/_base_client.py:1061\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1060\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1064\u001b[39m     cast_to=cast_to,\n\u001b[32m   1065\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1069\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1070\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 496\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResultados salvos em \u001b[39m\u001b[33m'\u001b[39m\u001b[33mitens_processados.xlsx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 484\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m filtro = DocumentFilter()\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Processa a tabela\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m df_limpo = \u001b[43mfiltro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocessa_tabela\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtabelaInicial.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# Exibe os resultados\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mItens processados (unificados):\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 434\u001b[39m, in \u001b[36mDocumentFilter.processa_tabela\u001b[39m\u001b[34m(self, caminho)\u001b[39m\n\u001b[32m    432\u001b[39m                 erros_processamento += \u001b[32m1\u001b[39m\n\u001b[32m    433\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAPI OpenAI\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    435\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m❌ Erro grave no processamento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# Cria o DataFrame final\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 424\u001b[39m, in \u001b[36mDocumentFilter.processa_tabela\u001b[39m\u001b[34m(self, caminho)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m         resultado = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    426\u001b[39m             resultado \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m resultado[\u001b[33m\"\u001b[39m\u001b[33mitem_normalizado\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m itens_processados\n\u001b[32m    428\u001b[39m         ):\n\u001b[32m    429\u001b[39m             resultados.append(resultado)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 335\u001b[39m, in \u001b[36mDocumentFilter._process_item\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minsufficient_quota\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️  ERRO DE QUOTA DA API OPENAI - Verifique sua chave API\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mErro de quota da API OpenAI - Processamento interrompido\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m     )\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minvalid_api_key\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m    339\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️  CHAVE API INVÁLIDA - Verifique sua chave API\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: Erro de quota da API OpenAI - Processamento interrompido"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Carrega variáveis de ambiente (incluindo OPENAI_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# Template do prompt para análise de itens\n",
    "ITEM_ANALYSIS_TEMPLATE = \"\"\"Analise o seguinte item e forneça uma normalização seguindo ESTRITAMENTE as regras e exemplos abaixo:\n",
    "\n",
    "REGRAS DE NORMALIZAÇÃO:\n",
    "\n",
    "1. REGRA PRINCIPAL - Unificação de Medidas:\n",
    "   - SEMPRE ignore TODAS as unidades de medida (ml, g, mg, kg, etc)\n",
    "   - SEMPRE ignore TODAS as quantidades (10 comp, 20 comp, 3 ampolas, etc)\n",
    "   - SEMPRE unifique itens com mesmo nome base, independente das medidas\n",
    "   - Mantenha apenas especificações que mudam a função do produto (ex: FPS)\n",
    "\n",
    "2. Para MARCAS:\n",
    "   - Em cosméticos e materiais: converta para termo genérico\n",
    "   - Em medicamentos: mantenha o nome específico\n",
    "\n",
    "EXEMPLOS DE CONVERSÃO DE MARCAS:\n",
    "- \"Nescau\" → \"Achocolatado em Pó\"\n",
    "- \"Nestogeno\" → \"Fórmula Infantil\"\n",
    "- \"Neutrogena Sun Fresh\" → \"Protetor Solar\"\n",
    "- \"Neosoro\" → \"Soro Fisiológico\"\n",
    "- \"Novalgina\" → \"Dipirona\"\n",
    "- \"Neutrofer\" → \"Sulfato Ferroso\"\n",
    "- \"Ninho\" → \"Leite em Pó\"\n",
    "- \"Neuleptil\" → \"Periciazina\"\n",
    "- \"Nestonutri\" → \"Suplemento Alimentar\"\n",
    "\n",
    "EXEMPLOS DE UNIFICAÇÃO:\n",
    "- \"Soro fisiológico 100ml\" e \"Soro fisiológico 500ml\" → \"Soro fisiológico\"\n",
    "- \"Dipirona 500mg\" e \"Dipirona 1g\" → \"Dipirona\"\n",
    "- \"Papel A4 500 folhas\" e \"Papel A4 100 folhas\" → \"Papel A4\"\n",
    "- \"Álcool 70% 1L\" e \"Álcool 70% 100ml\" → \"Álcool 70%\"\n",
    "- \"Protetor Solar FPS 30 50ml\" e \"Protetor Solar FPS 30 200ml\" → \"Protetor Solar FPS 30\"\n",
    "- \"Luva M cx 100un\" e \"Luva M cx 50un\" → \"Luva M\"\n",
    "- \"Fralda G 20un\" e \"Fralda G 60un\" → \"Fralda G\"\n",
    "\n",
    "EXEMPLOS DE MARCAS:\n",
    "- \"Neutrogena Sun Fresh FPS 30 200ml\" → \"Protetor Solar FPS 30\"\n",
    "- \"Novalgina 500mg 20 comp\" → \"Novalgina\"\n",
    "- \"Nescau 400g\" e \"Nescau 1kg\" → \"achocolatado em pó\"\n",
    "\n",
    "IMPORTANTE:\n",
    "- SEMPRE converta marcas para nomes genéricos dos produtos\n",
    "- Analise o contexto para identificar o produto real\n",
    "- Use termos técnicos/genéricos em vez de marcas\n",
    "- Mantenha apenas características funcionais (FPS, Zero Lactose, etc)\n",
    "- Use letras maiúsculas no início de cada palavra importante\n",
    "- NUNCA faça distinção por quantidade ou unidade de medida\n",
    "- Mantenha apenas características que alteram a função (tamanho P/M/G, FPS, etc)\n",
    "- Unifique SEMPRE produtos com mesmo nome base\n",
    "- Remova TODAS as informações de quantidade/volume/peso\n",
    "\n",
    "Item para análise:\n",
    "- Produto: {item}\n",
    "- Grupo: {grupo}\n",
    "- Já processado antes?: {ja_processado}\n",
    "- Produtos similares já processados: {produtos_similares}\n",
    "\n",
    "Responda APENAS no seguinte formato JSON:\n",
    "{{\"item_normalizado\": \"Nome Genérico Com Capitalize\", \"categoria\": \"categoria do item\"}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DocumentFilter:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"item\", \"grupo\", \"ja_processado\", \"produtos_similares\"],\n",
    "            template=ITEM_ANALYSIS_TEMPLATE,\n",
    "        )\n",
    "\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt, verbose=True)\n",
    "\n",
    "        # Dicionário para armazenar itens normalizados e suas variantes\n",
    "        self.normalized_items = (\n",
    "            {}\n",
    "        )  # chave: item_normalizado, valor: {código, categoria, variantes[]}\n",
    "        # Contador para geração de códigos sequenciais\n",
    "        self.current_code = 25000\n",
    "\n",
    "    def _get_next_code(self) -> int:\n",
    "        \"\"\"Retorna o próximo código disponível.\"\"\"\n",
    "        code = self.current_code\n",
    "        self.current_code += 1\n",
    "        return code\n",
    "\n",
    "    def _get_similar_items(self, item: str) -> str:\n",
    "        \"\"\"Retorna itens similares já processados.\"\"\"\n",
    "        similares = []\n",
    "        # Normaliza o item atual para comparação\n",
    "        palavras_item = set(item.lower().split())\n",
    "\n",
    "        # Remove palavras comuns que não ajudam na comparação\n",
    "        palavras_para_remover = {\n",
    "            \"ml\",\n",
    "            \"mg\",\n",
    "            \"g\",\n",
    "            \"kg\",\n",
    "            \"comp\",\n",
    "            \"comprimido\",\n",
    "            \"cx\",\n",
    "            \"c/\",\n",
    "            \"com\",\n",
    "            \"amp\",\n",
    "            \"ampola\",\n",
    "            \"gts\",\n",
    "            \"gotas\",\n",
    "            \"caps\",\n",
    "            \"capsula\",\n",
    "            \"un\",\n",
    "            \"unidade\",\n",
    "            \"pct\",\n",
    "            \"pacote\",\n",
    "            \"1\",\n",
    "            \"2\",\n",
    "            \"3\",\n",
    "            \"4\",\n",
    "            \"5\",\n",
    "            \"6\",\n",
    "            \"7\",\n",
    "            \"8\",\n",
    "            \"9\",\n",
    "            \"0\",\n",
    "        }\n",
    "        palavras_item = palavras_item - palavras_para_remover\n",
    "\n",
    "        for norm_item, details in self.normalized_items.items():\n",
    "            for variante in details[\"variantes\"]:\n",
    "                # Normaliza a variante para comparação\n",
    "                palavras_variante = (\n",
    "                    set(variante.lower().split()) - palavras_para_remover\n",
    "                )\n",
    "\n",
    "                # Calcula a interseção das palavras\n",
    "                palavras_comuns = palavras_item.intersection(palavras_variante)\n",
    "\n",
    "                # Se houver pelo menos 2 palavras em comum e uma delas for a primeira palavra\n",
    "                if len(palavras_comuns) >= 2:\n",
    "                    similares.append(f\"{variante} → {norm_item}\")\n",
    "                # Ou se a primeira palavra for exatamente igual\n",
    "                elif (list(palavras_item)[0] if palavras_item else \"\") == (\n",
    "                    list(palavras_variante)[0] if palavras_variante else \"\"\n",
    "                ):\n",
    "                    similares.append(f\"{variante} → {norm_item}\")\n",
    "\n",
    "        return json.dumps(similares, ensure_ascii=False) if similares else \"[]\"\n",
    "\n",
    "    def _is_similar_to_existing(\n",
    "        self, item: str, item_normalizado: str\n",
    "    ) -> tuple[bool, str | None]:\n",
    "        \"\"\"\n",
    "        Verifica se um item é similar a algum item já normalizado.\n",
    "        Retorna uma tupla (é_similar, item_normalizado_existente).\n",
    "        \"\"\"\n",
    "        palavras_item = set(item.lower().split())\n",
    "        palavras_norm = set(item_normalizado.lower().split())\n",
    "\n",
    "        # Remove palavras comuns que não ajudam na comparação\n",
    "        palavras_para_remover = {\n",
    "            \"ml\",\n",
    "            \"mg\",\n",
    "            \"g\",\n",
    "            \"kg\",\n",
    "            \"comp\",\n",
    "            \"comprimido\",\n",
    "            \"cx\",\n",
    "            \"c/\",\n",
    "            \"com\",\n",
    "            \"amp\",\n",
    "            \"ampola\",\n",
    "            \"gts\",\n",
    "            \"gotas\",\n",
    "            \"caps\",\n",
    "            \"capsula\",\n",
    "            \"un\",\n",
    "            \"unidade\",\n",
    "            \"pct\",\n",
    "            \"pacote\",\n",
    "            \"1\",\n",
    "            \"2\",\n",
    "            \"3\",\n",
    "            \"4\",\n",
    "            \"5\",\n",
    "            \"6\",\n",
    "            \"7\",\n",
    "            \"8\",\n",
    "            \"9\",\n",
    "            \"0\",\n",
    "        }\n",
    "        palavras_item = palavras_item - palavras_para_remover\n",
    "        palavras_norm = palavras_norm - palavras_para_remover\n",
    "\n",
    "        for norm_item, details in self.normalized_items.items():\n",
    "            palavras_norm_existente = (\n",
    "                set(norm_item.lower().split()) - palavras_para_remover\n",
    "            )\n",
    "\n",
    "            # Verifica similaridade com o item normalizado existente\n",
    "            palavras_comuns_norm = palavras_norm.intersection(palavras_norm_existente)\n",
    "            if len(palavras_comuns_norm) >= 2:\n",
    "                return True, norm_item\n",
    "\n",
    "            # Verifica similaridade com as variantes\n",
    "            for variante in details[\"variantes\"]:\n",
    "                palavras_variante = (\n",
    "                    set(variante.lower().split()) - palavras_para_remover\n",
    "                )\n",
    "                palavras_comuns = palavras_item.intersection(palavras_variante)\n",
    "\n",
    "                if len(palavras_comuns) >= 2:\n",
    "                    return True, norm_item\n",
    "                # Ou se a primeira palavra for exatamente igual\n",
    "                elif (list(palavras_item)[0] if palavras_item else \"\") == (\n",
    "                    list(palavras_variante)[0] if palavras_variante else \"\"\n",
    "                ):\n",
    "                    return True, norm_item\n",
    "\n",
    "        return False, None\n",
    "\n",
    "    def _process_item(self, row: pd.Series) -> Dict[str, str]:\n",
    "        \"\"\"Processa um único item usando a chain do LangChain.\"\"\"\n",
    "        item = str(row[\"Produto/Serviço\"])\n",
    "        grupo = str(row[\"Grupo\"])\n",
    "\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processando item: {item}\")\n",
    "        print(f\"Grupo: {grupo}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        try:\n",
    "            print(\"→ Verificando itens similares...\")\n",
    "            produtos_similares = self._get_similar_items(item)\n",
    "            print(f\"→ Produtos similares encontrados: {produtos_similares}\")\n",
    "\n",
    "            print(\"\\n→ Enviando para processamento LLM...\")\n",
    "            response = self.chain.invoke(\n",
    "                {\n",
    "                    \"item\": item,\n",
    "                    \"grupo\": grupo,\n",
    "                    \"ja_processado\": str(\n",
    "                        any(\n",
    "                            item in details[\"variantes\"]\n",
    "                            for details in self.normalized_items.values()\n",
    "                        )\n",
    "                    ),\n",
    "                    \"produtos_similares\": produtos_similares,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if not response or not response.get(\"text\"):\n",
    "                raise ValueError(\"Resposta vazia do LLM\")\n",
    "\n",
    "            print(\"✓ Resposta recebida do LLM\")\n",
    "            print(f\"→ Resposta bruta: {response['text']}\")\n",
    "\n",
    "            result = eval(response[\"text\"])  # Converte a string JSON em dicionário\n",
    "            print(f\"→ Item normalizado: {result['item_normalizado']}\")\n",
    "            print(f\"→ Categoria: {result['categoria']}\")\n",
    "\n",
    "            # Garante que o item_normalizado está com capitalize\n",
    "            item_normalizado = \" \".join(\n",
    "                word.capitalize() for word in result[\"item_normalizado\"].split()\n",
    "            )\n",
    "\n",
    "            # Verifica se já existe um item normalizado igual ou similar\n",
    "            print(\"\\n→ Verificando similaridade com itens existentes...\")\n",
    "            is_similar, existing_norm_item = self._is_similar_to_existing(\n",
    "                item, item_normalizado\n",
    "            )\n",
    "\n",
    "            if is_similar and existing_norm_item:\n",
    "                print(f\"✓ Item similar encontrado: {existing_norm_item}\")\n",
    "                # Adiciona como variante do item similar existente\n",
    "                self.normalized_items[existing_norm_item][\"variantes\"].append(item)\n",
    "                return {\n",
    "                    \"codigo\": self.normalized_items[existing_norm_item][\"codigo\"],\n",
    "                    \"item_normalizado\": existing_norm_item,\n",
    "                    \"categoria\": result[\"categoria\"],\n",
    "                    \"grupo_original\": grupo,\n",
    "                    \"unidade\": row[\"UND\"],\n",
    "                    \"variantes\": self.normalized_items[existing_norm_item][\"variantes\"],\n",
    "                }\n",
    "            elif item_normalizado in self.normalized_items:\n",
    "                print(f\"✓ Item idêntico encontrado: {item_normalizado}\")\n",
    "                # Adiciona como variante do item normalizado existente\n",
    "                self.normalized_items[item_normalizado][\"variantes\"].append(item)\n",
    "                return {\n",
    "                    \"codigo\": self.normalized_items[item_normalizado][\"codigo\"],\n",
    "                    \"item_normalizado\": item_normalizado,\n",
    "                    \"categoria\": result[\"categoria\"],\n",
    "                    \"grupo_original\": grupo,\n",
    "                    \"unidade\": row[\"UND\"],\n",
    "                    \"variantes\": self.normalized_items[item_normalizado][\"variantes\"],\n",
    "                }\n",
    "            else:\n",
    "                print(\"✓ Novo item único - criando novo registro\")\n",
    "                # Cria novo item normalizado\n",
    "                novo_item = {\n",
    "                    \"codigo\": self._get_next_code(),\n",
    "                    \"item_normalizado\": item_normalizado,\n",
    "                    \"categoria\": result[\"categoria\"],\n",
    "                    \"grupo_original\": grupo,\n",
    "                    \"unidade\": row[\"UND\"],\n",
    "                    \"variantes\": [item],\n",
    "                }\n",
    "                self.normalized_items[item_normalizado] = {\n",
    "                    \"codigo\": novo_item[\"codigo\"],\n",
    "                    \"categoria\": result[\"categoria\"],\n",
    "                    \"variantes\": [item],\n",
    "                }\n",
    "                return novo_item\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ ERRO no processamento LLM:\")\n",
    "            print(f\"Tipo de erro: {type(e).__name__}\")\n",
    "            print(f\"Mensagem de erro: {str(e)}\")\n",
    "\n",
    "            if \"insufficient_quota\" in str(e):\n",
    "                print(\"⚠️  ERRO DE QUOTA DA API OPENAI - Verifique sua chave API\")\n",
    "                raise Exception(\n",
    "                    \"Erro de quota da API OpenAI - Processamento interrompido\"\n",
    "                )\n",
    "            elif \"invalid_api_key\" in str(e):\n",
    "                print(\"⚠️  CHAVE API INVÁLIDA - Verifique sua chave API\")\n",
    "                raise Exception(\n",
    "                    \"Chave API OpenAI inválida - Processamento interrompido\"\n",
    "                )\n",
    "\n",
    "            print(\"\\n→ Usando fallback para processamento com erro...\")\n",
    "            # Em caso de erro, retorna o item original com capitalize\n",
    "            item_normalizado = \" \".join(word.capitalize() for word in item.split())\n",
    "            return {\n",
    "                \"codigo\": self._get_next_code(),\n",
    "                \"item_normalizado\": item_normalizado,\n",
    "                \"categoria\": \"não classificado\",\n",
    "                \"grupo_original\": grupo,\n",
    "                \"unidade\": row[\"UND\"],\n",
    "                \"variantes\": [item],\n",
    "            }\n",
    "\n",
    "    def processa_tabela(self, caminho: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Processa uma tabela Excel contendo itens para normalização e categorização.\n",
    "\n",
    "        Args:\n",
    "            caminho: Caminho para o arquivo Excel contendo os itens.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame com as colunas: codigo, item_normalizado, categoria, grupo_original, unidade, variantes\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"INICIANDO PROCESSAMENTO DA TABELA\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Carrega o DataFrame\n",
    "        print(f\"\\n→ Carregando arquivo: {caminho}\")\n",
    "        df = pd.read_excel(caminho)\n",
    "        print(f\"✓ Total de linhas carregadas: {len(df)}\")\n",
    "\n",
    "        # Limita aos 30 primeiros itens\n",
    "        df = df.head(30)\n",
    "        print(f\"→ Limitando aos primeiros 30 itens\")\n",
    "\n",
    "        # Verifica se existem as colunas necessárias\n",
    "        print(\"\\n→ Verificando colunas necessárias...\")\n",
    "        colunas_necessarias = [\"Código\", \"Grupo\", \"Produto/Serviço\", \"UND\"]\n",
    "        colunas_faltantes = [\n",
    "            col for col in colunas_necessarias if col not in df.columns\n",
    "        ]\n",
    "\n",
    "        if colunas_faltantes:\n",
    "            print(\"❌ ERRO: Colunas faltantes encontradas!\")\n",
    "            raise ValueError(\n",
    "                f\"O arquivo Excel deve conter as colunas: {', '.join(colunas_faltantes)}\"\n",
    "            )\n",
    "        print(\"✓ Todas as colunas necessárias encontradas\")\n",
    "\n",
    "        # Processa cada item\n",
    "        resultados = []\n",
    "        itens_processados = set()  # Conjunto para controlar itens já processados\n",
    "        itens_pulados = 0  # Contador de itens pulados\n",
    "        total_itens = 0  # Contador total de itens\n",
    "        erros_processamento = 0  # Contador de erros\n",
    "\n",
    "        print(\"\\nIniciando processamento de itens...\")\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            if pd.notna(row[\"Produto/Serviço\"]):\n",
    "                total_itens += 1\n",
    "                item = str(row[\"Produto/Serviço\"])\n",
    "\n",
    "                # Verifica se o item já foi processado através de uma variante\n",
    "                ja_processado = False\n",
    "                item_normalizado_encontrado = None\n",
    "                for norm_item, details in self.normalized_items.items():\n",
    "                    if item in details[\"variantes\"]:\n",
    "                        ja_processado = True\n",
    "                        item_normalizado_encontrado = norm_item\n",
    "                        break\n",
    "\n",
    "                if ja_processado:\n",
    "                    itens_pulados += 1\n",
    "                    print(f\"\\n→ Item pulado (já processado): {item}\")\n",
    "                    print(\n",
    "                        f\"  Já existe como variante de: {item_normalizado_encontrado}\"\n",
    "                    )\n",
    "                else:\n",
    "                    try:\n",
    "                        resultado = self._process_item(row)\n",
    "                        if (\n",
    "                            resultado is not None\n",
    "                            and resultado[\"item_normalizado\"] not in itens_processados\n",
    "                        ):\n",
    "                            resultados.append(resultado)\n",
    "                            itens_processados.add(resultado[\"item_normalizado\"])\n",
    "                    except Exception as e:\n",
    "                        erros_processamento += 1\n",
    "                        if \"API OpenAI\" in str(e):\n",
    "                            raise e\n",
    "                        print(f\"\\n❌ Erro grave no processamento: {str(e)}\")\n",
    "\n",
    "        # Cria o DataFrame final\n",
    "        df_resultado = pd.DataFrame(resultados)\n",
    "\n",
    "        # Reordena as colunas\n",
    "        colunas_ordem = [\n",
    "            \"codigo\",\n",
    "            \"item_normalizado\",\n",
    "            \"categoria\",\n",
    "            \"grupo_original\",\n",
    "            \"unidade\",\n",
    "            \"variantes\",\n",
    "        ]\n",
    "        df_resultado = df_resultado[colunas_ordem]\n",
    "\n",
    "        # Imprime o relatório de unificação\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"RELATÓRIO FINAL DE PROCESSAMENTO\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total de itens analisados: {total_itens}\")\n",
    "        print(f\"Itens pulados (já processados): {itens_pulados}\")\n",
    "        print(f\"Itens únicos após normalização: {len(resultados)}\")\n",
    "        print(f\"Erros de processamento: {erros_processamento}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if erros_processamento > 0:\n",
    "            print(\"\\n⚠️  ATENÇÃO: Houve erros durante o processamento!\")\n",
    "        else:\n",
    "            print(\"\\n✓ Processamento concluído com sucesso!\")\n",
    "\n",
    "        print(\"\\nRelatório de Unificação de Itens:\")\n",
    "        for item_norm, details in self.normalized_items.items():\n",
    "            print(f\"\\nItem Normalizado: {item_norm}\")\n",
    "            print(f\"Código: {details['codigo']}\")\n",
    "            print(f\"Categoria: {details['categoria']}\")\n",
    "            print(\"Variantes encontradas:\")\n",
    "            for var in details[\"variantes\"]:\n",
    "                print(f\"  - {var}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "        return df_resultado\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Função principal para demonstração do uso.\"\"\"\n",
    "    filtro = DocumentFilter()\n",
    "\n",
    "    # Processa a tabela\n",
    "    df_limpo = filtro.processa_tabela(\"tabelaInicial.xlsx\")\n",
    "\n",
    "    # Exibe os resultados\n",
    "    print(\"\\nItens processados (unificados):\")\n",
    "    print(df_limpo)\n",
    "\n",
    "    # Salva o resultado\n",
    "    df_limpo.to_excel(\"itens_processados.xlsx\", index=False)\n",
    "    print(\"\\nResultados salvos em 'itens_processados.xlsx'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
